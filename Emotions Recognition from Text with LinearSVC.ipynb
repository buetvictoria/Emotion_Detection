{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e0317c7",
   "metadata": {},
   "source": [
    "Emotions Recognition from Text with LinearSVC\n",
    "\n",
    "https://www.kaggle.com/code/rizkyalifr/emotions-recognition-from-text-with-linearsvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34f04c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\gk999ck\\anaconda3\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\gk999ck\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\gk999ck\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92fc8faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import nltk \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98d43529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d63fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c057db40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.txt\", delimiter=';', header=None, names=['sentence','label'])\n",
    "df_test = pd.read_csv(\"test.txt\", delimiter=';', header=None, names=['sentence','label'])\n",
    "df_val = pd.read_csv(\"val.txt\", delimiter=';', header=None, names=['sentence','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efd2e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_train, df_val]\n",
    "df = pd.concat(frames)\n",
    "df = df.reset_index()\n",
    "df = df.drop(columns = \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "195a16c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>im having ssa examination tomorrow in the morn...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>i constantly worry about their fight against n...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>i feel its important to share this info for th...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>i truly feel that if you are passionate enough...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>i feel like i just wanna buy any cute make up ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence    label\n",
       "0                                i didnt feel humiliated  sadness\n",
       "1      i can go from feeling so hopeless to so damned...  sadness\n",
       "2       im grabbing a minute to post i feel greedy wrong    anger\n",
       "3      i am ever feeling nostalgic about the fireplac...     love\n",
       "4                                   i am feeling grouchy    anger\n",
       "...                                                  ...      ...\n",
       "17995  im having ssa examination tomorrow in the morn...  sadness\n",
       "17996  i constantly worry about their fight against n...      joy\n",
       "17997  i feel its important to share this info for th...      joy\n",
       "17998  i truly feel that if you are passionate enough...      joy\n",
       "17999  i feel like i just wanna buy any cute make up ...      joy\n",
       "\n",
       "[18000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e1a02b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentence</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Total  Percent\n",
       "sentence      0      0.0\n",
       "label         0      0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def missing_percentage(df):\n",
    "    \"\"\"This function takes a DataFrame(df) as input and returns two columns, total missing values and total missing values percentage\"\"\"\n",
    "    total = df.isnull().sum().sort_values(ascending = False)\n",
    "    percent = round(df.isnull().sum().sort_values(ascending = False)/len(df)*100,2)\n",
    "    return pd.concat([total, percent], axis=1, keys=['Total','Percent'])\n",
    "\n",
    "missing_percentage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff150038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEJCAYAAACDscAcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAjmUlEQVR4nO3dcViUdb7//+cMiqIGzgywhto5R4HMjRxysMCSTktX1+XZ/a7rbp6zJzyJejJt6yRWevJsusc6YJmsGOa1ZrZl5zrr1gVbu55Ty4ULrVhNeVCz0og6ZoLAzCykAgPM/fuDnF8kJrfCDODr8Rf3Z+577vebmeHF575n7rEYhmEgIiLSS9ZwFyAiIoOLgkNERExRcIiIiCkKDhERMUXBISIipig4RETElGHhLiBUTpw4Ee4SREQGlYSEhB7HNeMQERFTFBwiImKKgkNERExRcIiIiCkKDhERMUXBISIipig4RETEFAWHiIiYErIPAJ4+fZqtW7fy+eefY7FYWLp0KQkJCRQUFNDQ0EBcXBzLly9nzJgxABQXF1NWVobVaiUnJwen0wlATU0NRUVF+P1+UlNTycnJwWKxhKoNEZHLXsiCY8eOHTidTlasWEFHRwdtbW0UFxeTkpLCnDlzKCkpoaSkhOzsbI4fP05lZSUbN27E5/Oxbt06Nm3ahNVqZdu2bSxZsoSkpCTy8vKoqqoiNTXVdD21Dy3uhy7715VPPhvuEkREQnOo6syZM3z44YfceuutAAwbNozRo0fjdrvJzMwEIDMzE7fbDYDb7SYjI4Phw4cTHx/PuHHjqK6uxufz0dLSQnJyMhaLhVmzZgW3ERGR0AjJjKO+vp7o6Gi2bNnC//3f/zFp0iQWLFhAU1MTNpsNAJvNRnNzMwBer5ekpKTg9na7Ha/XS0REBA6HIzjucDjwer097rO0tJTS0lIA8vPziY2N7XZ7bZ92GBrf7EFEJBxCEhydnZ18+umnLFy4kKSkJHbs2EFJScl51z/f16Cb+Xr0rKwssrKygsuNjY293nagGgo9iMjgEdaLHDocDhwOR3AWceONN/Lpp58SExODz+cDwOfzER0dHVzf4/EEt/d6vdjt9nPGPR4Pdrs9FC2IiMhXQhIcY8eOxeFwBC9tfujQISZMmIDL5aK8vByA8vJy0tLSAHC5XFRWVtLe3k59fT21tbUkJiZis9mIiori6NGjGIZBRUUFLpcrFC2IiMhXQvauqoULF1JYWEhHRwfx8fEsW7YMwzAoKCigrKyM2NhYcnNzAZg4cSLp6enk5uZitVpZtGgRVmtXxi1evJgtW7bg9/txOp0X9Y4qERG5eBbDzImDQeybX+Skt+OKiHw7fZGTiIj0CQWHiIiYouAQERFTFBwiImKKgkNERExRcIiIiCkKDhERMUXBISIipig4RETEFAWHiIiYouAQERFTFBwiImKKgkNERExRcIiIiCkKDhERMUXBISIipig4RETEFAWHiIiYouAQERFTFBwiImKKgkNEREwZFu4CpH8s+PW+cJdg2vN3pYe7BBHpBc04RETEFAWHiIiYouAQERFTQnaO495772XkyJFYrVYiIiLIz8/n1KlTFBQU0NDQQFxcHMuXL2fMmDEAFBcXU1ZWhtVqJScnB6fTCUBNTQ1FRUX4/X5SU1PJycnBYrGEqg0RkcteSE+Or1mzhujo6OBySUkJKSkpzJkzh5KSEkpKSsjOzub48eNUVlayceNGfD4f69atY9OmTVitVrZt28aSJUtISkoiLy+PqqoqUlNTQ9mGiMhlLayHqtxuN5mZmQBkZmbidruD4xkZGQwfPpz4+HjGjRtHdXU1Pp+PlpYWkpOTsVgszJo1K7iNiIiERkhnHI8//jgAt912G1lZWTQ1NWGz2QCw2Ww0NzcD4PV6SUpKCm5nt9vxer1ERETgcDiC4w6HA6/X2+O+SktLKS0tBSA/P5/Y2Nhut9f2XVsh880ehpqh3p/IUBGy4Fi3bh12u52mpiYee+wxEhISzruuYRimxnuSlZVFVlZWcLmxsbH3xQ5QQ6GHbzPU+xMZbM73dzpkh6rsdjsAMTExpKWlUV1dTUxMDD6fDwCfzxc8/+FwOPB4PMFtvV4vdrv9nHGPxxO8XxERCY2QBEdraystLS3Bnw8ePMhVV12Fy+WivLwcgPLyctLS0gBwuVxUVlbS3t5OfX09tbW1JCYmYrPZiIqK4ujRoxiGQUVFBS6XKxQtiIjIV0JyqKqpqYkNGzYA0NnZyU033YTT6WTy5MkUFBRQVlZGbGwsubm5AEycOJH09HRyc3OxWq0sWrQIq7Ur4xYvXsyWLVvw+/04nU69o0pEJMQshpkTB4PYiRMnui3XPrQ4TJVcvCuffLbX6+paVSJyqcJ+jkNERIYGBYeIiJii4BAREVMUHCIiYoqCQ0RETFFwiIiIKQoOERExRcEhIiKmKDhERMQUBYeIiJii4BAREVMUHCIiYoqCQ0RETFFwiIiIKQoOERExRcEhIiKmKDhERMQUBYeIiJii4BAREVMUHCIiYoqCQ0RETFFwiIiIKQoOERExRcEhIiKmKDhERMSUYaHcWSAQYNWqVdjtdlatWsWpU6coKCigoaGBuLg4li9fzpgxYwAoLi6mrKwMq9VKTk4OTqcTgJqaGoqKivD7/aSmppKTk4PFYgllGyIil7WQzjh2797N+PHjg8slJSWkpKRQWFhISkoKJSUlABw/fpzKyko2btzI6tWr2b59O4FAAIBt27axZMkSCgsLqauro6qqKpQtiIhc9kIWHB6Ph/379/O9730vOOZ2u8nMzAQgMzMTt9sdHM/IyGD48OHEx8czbtw4qqur8fl8tLS0kJycjMViYdasWcFtREQkNEJ2qOr5558nOzublpaW4FhTUxM2mw0Am81Gc3MzAF6vl6SkpOB6drsdr9dLREQEDocjOO5wOPB6vT3ur7S0lNLSUgDy8/OJjY3tdntt37QVUt/sYagZ6v2JDBUhCY733nuPmJgYJk2axOHDhy+4vmEYpsZ7kpWVRVZWVnC5sbGx19sOVEOhh28z1PsTGWwSEhJ6HA9JcBw5coR3332X//3f/8Xv99PS0kJhYSExMTH4fD5sNhs+n4/o6Gigaybh8XiC23u9Xux2+znjHo8Hu90eihZEROQrITnH8Y//+I9s3bqVoqIiHnjgAa699lruv/9+XC4X5eXlAJSXl5OWlgaAy+WisrKS9vZ26uvrqa2tJTExEZvNRlRUFEePHsUwDCoqKnC5XKFoQUREvhLSt+N+05w5cygoKKCsrIzY2Fhyc3MBmDhxIunp6eTm5mK1Wlm0aBFWa1fGLV68mC1btuD3+3E6naSmpoazBRGRy47FMHPiYBA7ceJEt+XahxaHqZKLd+WTz/Z63QW/3tePlfSP5+9KD3cJIvI15zvHoU+Oi4iIKQoOERExRcEhIiKmKDhERMQUBYeIiJii4BAREVMUHCIiYoqCQ0RETOl1cLz66qs9jv/+97/vs2JERGTg63VwvPLKK6bGRURkaLrgtaref/99oOtrX8/+fNbJkyeJiorqn8pERGRAumBwPPPMMwD4/f7gzwAWi4WxY8eycOHC/qtOREQGnAsGR1FREQBPP/00P/vZz/q9IBERGdh6fVn1r4dGIBDodtvZS56LiMjQ1+vgqKmpYfv27Rw7dgy/39/ttt/85jd9XpiIiAxMvQ6OoqIipk+fztKlSxkxYkR/1iQiIgNYr4OjsbGRn/70p1gslv6sR0REBrhen5xIS0vjwIED/VmLiIgMAr2ecbS3t7NhwwamTJnC2LFju92md1uJiFw+eh0cEyZMYMKECf1Zi4iIDAK9Do477rijP+sQEZFBotfB8c3LjXzdtdde2yfFiIjIwNfr4Pj65UYAmpub6ejowOFw8PTTT/d5YSIiMjCZ+hzH1wUCAV555RVd5FBE5DJz0dcKsVqtzJ07l9/97nd9WY+IiAxwvZ5x9OTgwYO9uk6V3+9nzZo1dHR00NnZyY033si8efM4deoUBQUFNDQ0EBcXx/LlyxkzZgwAxcXFlJWVYbVaycnJwel0Al2XPikqKsLv95OamkpOTo4+lCgiEkK9Do6lS5d2W/b7/fj9fhYvXnzBbYcPH86aNWsYOXIkHR0dPProozidTt555x1SUlKYM2cOJSUllJSUkJ2dzfHjx6msrGTjxo34fD7WrVvHpk2bsFqtbNu2jSVLlpCUlEReXh5VVVWkpqaa71xERC5Kr4Pjvvvu67Y8YsQIrrzySkaNGnXBbS0WCyNHjgSgs7OTzs5OLBYLbrebtWvXApCZmcnatWvJzs7G7XaTkZHB8OHDiY+PZ9y4cVRXVxMXF0dLSwvJyckAzJo1C7fbreAQEQmhXgfH1KlTga6T4k1NTcTExJi6nHogEGDlypXU1dVx++23k5SURFNTEzabDQCbzUZzczMAXq+XpKSk4LZ2ux2v10tERAQOhyM47nA48Hq9Pe6vtLSU0tJSAPLz84mNje12e22vKx84vtnDUDPU+xMZKnodHC0tLWzfvp3Kyko6OzuJiIggIyODhQsX9mrWYbVaefLJJzl9+jQbNmzg2LFj513XMAxT4z3JysoiKysruNzY2NjrbQeqodDDtxnq/YkMNgkJCT2O93rK8Nxzz9Ha2sqGDRvYuXMnGzZswO/389xzz5kqZPTo0UydOpWqqipiYmLw+XwA+Hw+oqOjga6ZhMfjCW7j9Xqx2+3njHs8Hux2u6n9i4jIpel1cFRVVXHfffeRkJDA8OHDSUhIYNmyZb26Ym5zczOnT58Guk6qHzp0iPHjx+NyuSgvLwegvLyctLQ0AFwuF5WVlbS3t1NfX09tbS2JiYnYbDaioqI4evQohmFQUVGBy+W6mL5FROQi9fpQVWRkJM3NzcTFxQXHmpubGTbswnfh8/koKioiEAhgGAbp6elMnz6d5ORkCgoKKCsrIzY2ltzcXAAmTpxIeno6ubm5WK1WFi1aFDyfsnjxYrZs2YLf78fpdOrEuIhIiFmMXp44eOWVV6ioqODv/u7viIuLo6GhgT/84Q/cfPPN/OQnP+nvOi/ZiRMnui3XPnThtxEPNFc++Wyv113w6339WEn/eP6u9HCXICJfc75zHL2eccydOxe73c6f//zn4DmHH/7wh9x66619VqSIiAx8vQ6OHTt2MHPmTH7+858Hx44cOcLzzz/PggUL+qM2EREZgHp9cnzv3r1Mnjy529ikSZP485//3OdFiYjIwNXr4LBYLAQCgW5jZ092i4jI5aPXwTFlyhT+67/+KxgegUCA3/72t0yZMqXfihMRkYGn1+c4cnJyyM/PZ8mSJcTGxtLY2IjNZmPlypX9WZ+IiAwwvQ4Oh8PB+vXrqa6uxuPx4HA4SExMNHW9KhERGfxMfR+H1WoNXplWREQuT5ouiIiIKQoOERExRcEhIiKmKDhERMQUBYeIiJii4BAREVNMvR1XZKB4/dXB963xt/+/K8Ndgkif0IxDRERMUXCIiIgpCg4RETFFwSEiIqYoOERExBQFh4iImKLgEBERUxQcIiJiij4AKDIAFRYWhrsEU+6///5wlyAhpBmHiIiYEpIZR2NjI0VFRfzlL3/BYrGQlZXF7NmzOXXqFAUFBTQ0NBAXF8fy5csZM2YMAMXFxZSVlWG1WsnJycHpdAJQU1NDUVERfr+f1NRUcnJysFgsoWhDREQI0YwjIiKC+fPnU1BQwOOPP87rr7/O8ePHKSkpISUlhcLCQlJSUigpKQHg+PHjVFZWsnHjRlavXs327dsJBAIAbNu2jSVLllBYWEhdXR1VVVWhaEFERL4SkuCw2WxMmjQJgKioKMaPH4/X68XtdpOZmQlAZmYmbrcbALfbTUZGBsOHDyc+Pp5x48ZRXV2Nz+ejpaWF5ORkLBYLs2bNCm4jIiKhEfJzHPX19Xz66ackJibS1NSEzWYDusKlubkZAK/Xi8PhCG5jt9vxer3njDscDrxeb2gbEBG5zIX0XVWtra089dRTLFiwgFGjRp13PcMwTI33pLS0lNLSUgDy8/OJjY3tdvvguyg35/Qw1Jjrb/A9gkP58RvKvcm5QhYcHR0dPPXUU9x8883ccMMNAMTExODz+bDZbPh8PqKjo4GumYTH4wlu6/V6sdvt54x7PB7sdnuP+8vKyiIrKyu43NjY2B9thdRQ6OHbqL/Bayj3djlLSEjocTwkh6oMw2Dr1q2MHz+e73//+8Fxl8tFeXk5AOXl5aSlpQXHKysraW9vp76+ntraWhITE7HZbERFRXH06FEMw6CiogKXyxWKFkRE5CshmXEcOXKEiooKrrrqKh566CEAfvrTnzJnzhwKCgooKysjNjaW3NxcACZOnEh6ejq5ublYrVYWLVqE1dqVcYsXL2bLli34/X6cTiepqamhaEFERL4SkuCYMmUKu3bt6vG2Rx99tMfxuXPnMnfu3HPGJ0+ezFNPPdWn9YmISO/pk+MiImKKgkNERExRcIiIiCkKDhERMUXBISIipig4RETEFAWHiIiYouAQERFTFBwiImKKgkNERExRcIiIiCkKDhERMSWkX+QkImL9cPBdpDRwzYpwlzCgaMYhIiKmKDhERMQUBYeIiJii4BAREVMUHCIiYoqCQ0RETFFwiIiIKQoOERExRcEhIiKmKDhERMQUBYeIiJii4BAREVMUHCIiYkpIro67ZcsW9u/fT0xMDE891XVlzFOnTlFQUEBDQwNxcXEsX76cMWPGAFBcXExZWRlWq5WcnBycTicANTU1FBUV4ff7SU1NJScnB4vFEooWRETkKyGZcdxyyy088sgj3cZKSkpISUmhsLCQlJQUSkpKADh+/DiVlZVs3LiR1atXs337dgKBAADbtm1jyZIlFBYWUldXR1VVVSjKFxGRrwlJcEydOjU4mzjL7XaTmZkJQGZmJm63OziekZHB8OHDiY+PZ9y4cVRXV+Pz+WhpaSE5ORmLxcKsWbOC24iISOiE7YucmpqasNlsANhsNpqbmwHwer0kJSUF17Pb7Xi9XiIiInA4HMFxh8OB1+s97/2XlpZSWloKQH5+PrGxsd1ur+2zTkLnmz0MNeb6G3yP4FB+/Mz0dv5X7cA1lB+7izHgvgHQMAxT4+eTlZVFVlZWcLmxsfGS6hoIhkIP30b9DV5mehuM78gZyo/dt0lISOhxPGyPYUxMDD6fDwCfz0d0dDTQNZPweDzB9bxeL3a7/Zxxj8eD3W4PbdEiIhK+4HC5XJSXlwNQXl5OWlpacLyyspL29nbq6+upra0lMTERm81GVFQUR48exTAMKioqcLlc4SpfROSyFZJDVb/85S/54IMP+PLLL7nnnnuYN28ec+bMoaCggLKyMmJjY8nNzQVg4sSJpKenk5ubi9VqZdGiRVitXfm2ePFitmzZgt/vx+l0kpqaGoryRUTka0ISHA888ECP448++miP43PnzmXu3LnnjE+ePDn4ORAREQmPwXieSkREwkjBISIipig4RETEFAWHiIiYouAQERFTFBwiImLKgLvkiIjIYPZS5c/CXYJpd2Y8bWp9zThERMQUBYeIiJii4BAREVMUHCIiYoqCQ0RETFFwiIiIKQoOERExRcEhIiKmKDhERMQUBYeIiJii4BAREVMUHCIiYoqCQ0RETFFwiIiIKQoOERExRcEhIiKmKDhERMQUBYeIiJgyKL86tqqqih07dhAIBPje977HnDlzwl2SiMhlY9DNOAKBANu3b+eRRx6hoKCAvXv3cvz48XCXJSJy2Rh0wVFdXc24ceP4zne+w7Bhw8jIyMDtdoe7LBGRy4bFMAwj3EWY8dZbb1FVVcU999wDQEVFBR9//DGLFi3qtl5paSmlpaUA5Ofnh7xOEZGhatDNOHrKOYvFcs5YVlYW+fn5YQmNVatWhXyfoTKUewP1N9ipv9AYdMHhcDjweDzBZY/Hg81mC2NFIiKXl0EXHJMnT6a2tpb6+no6OjqorKzE5XKFuywRkcvGoHs7bkREBAsXLuTxxx8nEAjwt3/7t0ycODHcZXWTlZUV7hL6zVDuDdTfYKf+QmPQnRwXEZHwGnSHqkREJLwUHCIiYoqC4xL827/9W7hL6Ff19fWsWLEi3GVIL+3evZvly5dTWFgY7lL63Pz588NdwoCWl5fH6dOnQ7a/QXdyfCB57LHHwl2CDACGYWAYBlZreP8Pe+ONN3jkkUeIj4+/6PsIBAJh70Ogs7OTiIiIC6539rn3r//6ryGo6v+n4LgE8+fP54UXXmDnzp1UVVUB8OMf/5iMjAw2b97MjTfeSFpaGgCFhYVkZGSE5a3Dra2tFBQU4PV6CQQC/PjHP+bEiRO89957+P1+kpOTufvuu7FYLNTU1PDMM88QGRnJlClTgvfxpz/9iXfffZe2tjZOnjzJjBkzyM7OBuDAgQPs2rWLjo4OvvOd77Bs2TJGjhzJSy+9xLvvvktERATXXXcd//RP/8S+fft4+eWXsVqtjBo1il/84hf91vcTTzyBx+Ohvb2d2bNnk5WVxfz585k9ezb79+8nMjKShx56iLFjx1JXV8fmzZsJBAI4nU5+//vf8+KLLwLw6quvsm/fPtrb25kxYwbz5s2jvr6evLw8vvvd73L06FEeeugh4uLi+q2XC/nVr37FyZMnWb9+PTNnzqSuro7PP/+czs5O7rjjDtLS0qivr+fpp5+mra0NgIULF3L11Vdz+PBhXn75ZcaOHctnn31GQUFB2Pq4EMMweny9FRQUkJmZyfXXXw9AUVER06dPZ8aMGbz00kt88MEHtLe3c/vtt3PbbbeFrN6eXnsvvfQSeXl5REdH88knn/Diiy+ydu1adu3ahc/no6GhgSuuuIJp06bxzjvv0N7eTn19PTfddBN33HFHj8+9tWvXkpeXR2Rk5Dn7y8jIoKamhl//+te0trYSHR3NsmXLLu3zb4ZctOzsbGPfvn3Gv//7vxudnZ2Gz+cz7rnnHsPr9RqHDx821q9fbxiGYZw+fdpYtmyZ0dHREZY69+3bZzzzzDPB5dOnTxtffvllcLmwsNBwu92GYRjGihUrjMOHDxuGYRgvvPCCkZubaxiGYezZs8e49957jdOnTxttbW3G0qVLjYaGBqOpqcl49NFHjZaWFsMwDKO4uNj47W9/a3z55ZfG/fffbwQCAcMwDOPUqVOGYRhGbm6u4fF4uo31l7M9trW1Gbm5uUZzc7Nxxx13BHt98cUXjZdfftkwDMPIy8sz3nzzTcMwDOP11183srOzDcMwjKqqKmPr1q1GIBAwOjs7jby8POPw4cPGyZMnjXnz5hlHjhzp1x7MWLZsmdHU1GS89NJLRnl5uWEYXb/j+++/32hpaTFaW1uNtrY2wzAM48SJE8bKlSsNwzCM999/38jOzjZOnjwZttov5Ozjcb7X29tvv21s3rzZMAzDaG9vN+655x6jra3N+OMf/xh8jP1+v7Fy5cqQ9tnTa+/s42QYhlFdXW2sWbPGMAzD+M1vfmM8/PDDwcdoz549xj//8z8bzc3NwedwdXV1j8+9s/fZ0/7a29uN1atXB/e5d+9eo6io6JL60ozjEn300UfMnDkTq9XK2LFjmTp1Kp988gkul4vt27fT1NTE22+/zQ033NCrqWd/uOqqq3jxxRfZuXMn06dP55prruGtt97i1Vdfpa2tjVOnTjFx4kSmTp3K6dOnmTp1KgCzZs0K/mcHcO211zJq1CgAJkyYQGNjI6dPn+b48eP8/Oc/B6Cjo4Pk5GSioqKIjIxk69atXH/99UyfPh2Aq6++mqKiItLT07nhhhv6te/du3cHL4DZ2NhIbW0tw4YNC9YyadIkDh48CBD8zw3gpptuCs42Dhw4wMGDB3n44YeBrv8g6+rqiI2NJTY2luTk5H7t4WIcPHiQ9957j9deew0Av99PY2Mjdrud7du389lnn2G1WqmtrQ1uk5iYeEmHuELlfK83p9PJjh07aG9vp6qqimuuuYbIyEgOHDjAsWPHeOuttwA4c+YMtbW1Ieu1p9fet3G5XERGRgaXr7vuOq644goAZsyYwUcffURaWtp5n3s97e/YsWN8/vnnrFu3Dug6HHmpV9tQcPSjm2++mTfffJPKykqWLl0atjoSEhJYv349+/fv5z//8z+ZNm0ar7/+Onl5ecTGxrJr1y78fj+GYfR43a+zhg8fHvzZarXS2dmJYRikpKTwwAMPnLP+f/zHf3Do0CEqKyv5n//5H9asWcPdd9/Nxx9/zP79+3n44Yd54okngi+MvnT48GEOHTrEY489xogRI1i7di3t7e1EREQEezzbw4XMmTPnnMMb9fX1jBw5ss/r7guGYbBixQoSEhK6je/atYuYmBiefPJJDMPgzjvvDN42YsSIUJfZpyIjI5k6dSoHDhygsrKSmTNnAl2/i5ycHJxOZ1jq6um1Z7Vag9fca29v77b+hR6Hs8/d8z33etrfjBkzmDBhAo8//ngfdNRFZ8Eu0TXXXMO+ffsIBAI0Nzfz4YcfkpiYCMAtt9zC7t27AcL66Xav10tkZCSzZs3iBz/4ATU1NQBER0fT2trK22+/DcDo0aMZNWoUH330EQBvvvnmBe87OTmZI0eOUFdXB0BbWxsnTpygtbWVM2fOcP3117NgwQI+++wzAOrq6khKSuLv//7vueKKK7pdd6wvnTlzhtGjRzNixAi++OILPv74429dPykpKfh7qKysDI5PmzaNPXv20NraCnT9Lpuamvql5r4ybdo0/vu//zv4x+nTTz8Fun4nNpsNq9VKRUUFgUAgnGVelG97vc2cOZM9e/bw0UcfBYPC6XTyxhtv0NHRARB8boZKT6+9+Pj44Gvw7EzofA4dOsSpU6fw+/243W6uvvpq0/tLSEigubmZo0ePAl1HBT7//PNL6kszjktgsViYMWNGt8Mc2dnZjB07FoCxY8cyfvz44AnycDl27Bg7d+7EYrEwbNgwFi9ejNvtZsWKFcTHxzN58uTgusuWLQueHJ82bdoF7zs6Opp7772XTZs2Bf97+od/+AeioqJ44oknaG9vxzAM7rrrLgB27twZPERy7bXX8ld/9Vf90HHXH4w//vGPPPjggyQkJJCUlPSt6y9YsIDNmzfz2muvcf311wcPyU2bNo0vvviC1atXA13/6d13330D+p1HP/nJT3j++ed58MEHAYiLi2PVqlXcfvvtPPXUU7z11lt897vfHZSzjG97vV133XU8/fTTuFwuhg3r+tN26623Ul9fz8qVK4Gu5+vZbUOhp9ee3+9n69atFBcXB0PvfK6++mo2b95MXV0dN910E5MnT6a+vt7U/oYNG8aKFSvYsWMHZ86cobOzk9mzZ1/SP7O65MhF+vLLL1m5ciVbtmw57zptbW08+OCDrF+/PviHSAamtrY2IiMjsVgs7N27l7179wbPa4iEw5/+9Cc++eSTc75raCDQjOMieL1efvGLX/CDH/zgvOscPHiQZ555hu9///sKjUGgpqaG5557DsMwGD16dFjPSYkMdJpxiIiIKQP3QK2IiAxICg4RETFFwSEiIqYoOET6yL333hv8JPq3mTdvXvBzL2ZdyrYifUXBISIipig4RETEFH2OQ6SPVVdXs2PHDr744gsiIyO54YYbuOuuu4KfZgbYv38/u3fvpqWlhVtuuYU777wz+Gn0srIyXnvtNf7yl7+QmJjI3XffHdZLtot8k2YcIn3MarVy1113sX37dh577DHef/99Xn/99W7ruN1u8vPzWb9+Pe+++y579uwB4J133qG4uJgVK1bw7LPPMmXKFDZt2hSONkTOS8Eh0scmTZpEcnIyERERxMfHk5WVxQcffNBtnR/+8IeMGTOG2NhYZs+ezd69ewEoLS3lRz/6ERMmTCAiIoIf/ehHfPbZZzQ0NISjFZEe6VCVSB87ceIEL7zwAp988gl+v5/Ozk4mTZrUbR2HwxH8OS4uDp/PB0BDQwM7duzghRdeCN5uGAZer1eHq2TAUHCI9LFnn32Wv/7rv+Zf/uVfiIqK4g9/+MM5l8/2eDzBq5M2NjYGv1gnNjaWuXPncvPNN4e8bpHe0qEqkT7W0tLCqFGjGDlyJF988QVvvPHGOeu8+uqrnDp1isbGRnbv3k1GRgYAt912GyUlJcHvSzhz5gz79u0Laf0iF6IZh0gfmz9/Pr/61a/43e9+x9/8zd+QkZHB+++/320dl8vFqlWrOHPmDLfccgu33nor0PV9E62trfzyl7+ksbGRUaNGkZKSQnp6ejhaEemRro4rIiKm6FCViIiYouAQERFTFBwiImKKgkNERExRcIiIiCkKDhERMUXBISIipig4RETElP8P/PsQzuANRN4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Melihat Sebaran Label\n",
    "import seaborn as sns\n",
    "sns.countplot(x ='label', data = df,order = df[\"label\"].value_counts().index)\n",
    " \n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f312df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "df['label_enc'] = labelencoder.fit_transform(df['label'])\n",
    "df_test['label_enc'] = labelencoder.transform(df_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ece7b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>surprise</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>joy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  label_enc\n",
       "0   sadness          4\n",
       "2     anger          0\n",
       "3      love          3\n",
       "6  surprise          5\n",
       "7      fear          1\n",
       "8       joy          2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map = df[['label','label_enc']].drop_duplicates(keep='first')\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf96ebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel(a) :\n",
    "    if a == 4 :\n",
    "        o = \"sadness\"\n",
    "    elif a == 0 :\n",
    "        o = \"anger\"\n",
    "    elif a == 3 :\n",
    "        o = \"love\"\n",
    "    elif a == 5 :\n",
    "        o = \"surprise\"\n",
    "    elif a == 1 :\n",
    "        o = \"fear\"\n",
    "    else :\n",
    "        o = \"joy\"\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92a2f3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>joy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>love</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>surprise</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  label_enc\n",
       "0    sadness          4\n",
       "3        joy          2\n",
       "5       fear          1\n",
       "6      anger          0\n",
       "14      love          3\n",
       "65  surprise          5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['label','label_enc']].drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da5344cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\GK999CK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    " import nltk\n",
    " nltk.download('punkt')\n",
    " from nltk.stem.porter import PorterStemmer\n",
    " from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    " porter_stemmer = PorterStemmer()    \n",
    "\n",
    " sentence_stemm_train = []\n",
    " for i in range(df.shape[0]):\n",
    "     word_data = df.sentence[i]\n",
    "     nltk_tokens = nltk.word_tokenize(word_data)\n",
    "     word=[]\n",
    "     for w in nltk_tokens:\n",
    "         word.append(porter_stemmer.stem(w))\n",
    "     sentence = TreebankWordDetokenizer().detokenize(word)\n",
    "     sentence_stemm_train.append(sentence)\n",
    "\n",
    " sentence_stemm_test = []\n",
    " for i in range(df_test.shape[0]):\n",
    "     word_data = df_test.sentence[i]\n",
    "     nltk_tokens = nltk.word_tokenize(word_data)\n",
    "     word=[]\n",
    "     for w in nltk_tokens:\n",
    "         word.append(porter_stemmer.stem(w))\n",
    "     sentence = TreebankWordDetokenizer().detokenize(word)\n",
    "     sentence_stemm_test.append(sentence)\n",
    "\n",
    " df[\"sentence_stemm\"] = np.array(sentence_stemm_train)\n",
    " df_test[\"sentence_stemm\"] = np.array(sentence_stemm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feb501ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Feature Setelah di Ekstrak : 3398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GK999CK\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, stop_words='english')\n",
    "\n",
    "# We transform each text into a vector\n",
    "features_train = tfidf.fit_transform(df.sentence).toarray()\n",
    "features_test = tfidf.transform(df_test.sentence).toarray()\n",
    "\n",
    "features_train_name = tfidf.get_feature_names()\n",
    "\n",
    "labels = df.label_enc\n",
    "\n",
    "print(\"Jumlah Feature Setelah di Ekstrak : \"+str(features_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6681aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train_df = pd.DataFrame(data=features_train,    # values,    # 1st column as index\n",
    "                                columns=features_train_name)  # 1st row as the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82003925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotions Recognition from Text with LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd069127",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#mencoba beberapa algoritma machine learning\n",
    "\n",
    "# models = [\n",
    "#     RandomForestClassifier,\n",
    "#     LinearSVC(),\n",
    "#     MultinomialNB(),XGBClassifier()\n",
    "# ]\n",
    "\n",
    "models = [LinearSVC()]\n",
    "\n",
    "# 5 Cross-validation\n",
    "CV = 10\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, features_train, labels, scoring='f1_macro', cv=CV)\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'f1_macro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f69cfa0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean F1_Macro</th>\n",
       "      <th>Standard deviation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.856706</td>\n",
       "      <td>0.008168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Mean F1_Macro  Standard deviation\n",
       "model_name                                   \n",
       "LinearSVC        0.856706            0.008168"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_f1 = cv_df.groupby('model_name').f1_macro.mean()\n",
    "std_f1 = cv_df.groupby('model_name').f1_macro.std()\n",
    "\n",
    "f1 = pd.concat([mean_f1, std_f1], axis= 1, \n",
    "          ignore_index=True)\n",
    "f1.columns = ['Mean F1_Macro', 'Standard deviation']\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e32ecddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC()\n",
    "model.fit(features_train, labels)\n",
    "y_pred = model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16d8e689",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cat = []\n",
    "for i in y_pred:\n",
    "  cat = relabel(i)\n",
    "  pred_cat.append(cat)\n",
    "pred_cat = np.array(pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "566a4e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.87      0.88      0.88       275\n",
      "        fear       0.88      0.86      0.87       224\n",
      "         joy       0.90      0.92      0.91       695\n",
      "        love       0.75      0.75      0.75       159\n",
      "     sadness       0.93      0.92      0.92       581\n",
      "    surprise       0.74      0.68      0.71        66\n",
      "\n",
      "    accuracy                           0.89      2000\n",
      "   macro avg       0.84      0.84      0.84      2000\n",
      "weighted avg       0.89      0.89      0.89      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test.label, pred_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b184dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(text):\n",
    "    x = tfidf.transform([text]).toarray()\n",
    "    pred = relabel(model.predict(x))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41b6c39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fear'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"i feeling anxious today\"\n",
    "predict_emotion(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9fa6bf89",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m EmotionPredictions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSampleSentimentCompanyReviews.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m text \u001b[38;5;241m=\u001b[39m EmotionPredictions\n\u001b[1;32m----> 4\u001b[0m \u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36mpredict_emotion\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_emotion\u001b[39m(text):\n\u001b[1;32m----> 2\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtfidf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[0;32m      3\u001b[0m     pred \u001b[38;5;241m=\u001b[39m relabel(model\u001b[38;5;241m.\u001b[39mpredict(x))\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pred\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2103\u001b[0m, in \u001b[0;36mTfidfVectorizer.transform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   2086\u001b[0m \u001b[38;5;124;03m\"\"\"Transform documents to document-term matrix.\u001b[39;00m\n\u001b[0;32m   2087\u001b[0m \n\u001b[0;32m   2088\u001b[0m \u001b[38;5;124;03mUses the vocabulary and document frequencies (df) learned by fit (or\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;124;03m    Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[0;32m   2100\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2101\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m, msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe TF-IDF vectorizer is not fitted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2103\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mtransform(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1387\u001b[0m, in \u001b[0;36mCountVectorizer.transform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_vocabulary()\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;66;03m# use the same matrix-building strategy as fit_transform\u001b[39;00m\n\u001b[1;32m-> 1387\u001b[0m _, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_vocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1389\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1209\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[0;32m   1208\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1209\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1210\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1211\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:111\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    113\u001b[0m         doc \u001b[38;5;241m=\u001b[39m tokenizer(doc)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:69\u001b[0m, in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m\"\"\"Chain together an optional series of text preprocessing steps to\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03mapply to a document.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    preprocessed string\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lower:\n\u001b[1;32m---> 69\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accent_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     doc \u001b[38;5;241m=\u001b[39m accent_function(doc)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5569\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5570\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5571\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5572\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5573\u001b[0m ):\n\u001b[0;32m   5574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "#New dataset in which predict emotions\n",
    "EmotionPredictions = pd.read_csv('SampleSentimentCompanyReviews.csv')\n",
    "text = EmotionPredictions\n",
    "predict_emotion(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59275bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
